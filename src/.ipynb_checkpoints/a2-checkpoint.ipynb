{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "# Alex Hobeychi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/hns_2018_2019.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Object ID           10000 non-null  int64  \n",
      " 1   Title               10000 non-null  object \n",
      " 2   Post Type           10000 non-null  object \n",
      " 3   Author              10000 non-null  object \n",
      " 4   Created At          10000 non-null  object \n",
      " 5   URL                 9420 non-null   object \n",
      " 6   Points              10000 non-null  int64  \n",
      " 7   Number of Comments  10000 non-null  float64\n",
      " 8   year                10000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 781.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>Created At</th>\n",
       "      <th>URL</th>\n",
       "      <th>Points</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16043981</td>\n",
       "      <td>Terminal: How the airport came to embody our n...</td>\n",
       "      <td>story</td>\n",
       "      <td>jseliger</td>\n",
       "      <td>2018-01-01 00:59:56</td>\n",
       "      <td>http://www.slate.com/articles/business/cover_s...</td>\n",
       "      <td>97</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16044958</td>\n",
       "      <td>Not only is it possible to beat Google, it cou...</td>\n",
       "      <td>story</td>\n",
       "      <td>Nuzzerino</td>\n",
       "      <td>2018-01-01 06:16:27</td>\n",
       "      <td>https://www.quora.com/Is-it-possible-to-beat-G...</td>\n",
       "      <td>92</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16045440</td>\n",
       "      <td>DC’s war on rats goes digital</td>\n",
       "      <td>story</td>\n",
       "      <td>fern12</td>\n",
       "      <td>2018-01-01 09:37:22</td>\n",
       "      <td>https://wamu.org/story/17/12/18/d-c-s-war-rats...</td>\n",
       "      <td>31</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16048365</td>\n",
       "      <td>Show HN: Bitcoin Arbitrage – Kraken vs. GDAX</td>\n",
       "      <td>show_hn</td>\n",
       "      <td>BigBalli</td>\n",
       "      <td>2018-01-01 22:21:21</td>\n",
       "      <td>http://giacomoballi.com/crypto.html</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16050632</td>\n",
       "      <td>Handy function for Bash to display the compile...</td>\n",
       "      <td>story</td>\n",
       "      <td>ikromin</td>\n",
       "      <td>2018-01-02 08:19:13</td>\n",
       "      <td>https://www.igorkromin.net/index.php/2018/01/0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16050939</td>\n",
       "      <td>Is debate around 'bias in AI' driven by human ...</td>\n",
       "      <td>story</td>\n",
       "      <td>imartin2k</td>\n",
       "      <td>2018-01-02 09:49:43</td>\n",
       "      <td>http://donaldclarkplanb.blogspot.com/2017/12/i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16051647</td>\n",
       "      <td>Cryptocurrencies Are Not a Legal Tender; India...</td>\n",
       "      <td>story</td>\n",
       "      <td>techaddict009</td>\n",
       "      <td>2018-01-02 13:15:06</td>\n",
       "      <td>https://cryptocrimson.com/cryptocurrencies-not...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16051717</td>\n",
       "      <td>Tech's Winning (and Losing) Jobs in 2018</td>\n",
       "      <td>story</td>\n",
       "      <td>SunTzu9087</td>\n",
       "      <td>2018-01-02 13:30:45</td>\n",
       "      <td>https://insights.dice.com/2018/01/02/tech-winn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16051971</td>\n",
       "      <td>Build a URL Shortener Using AWS Lambda and S3</td>\n",
       "      <td>story</td>\n",
       "      <td>dan9408</td>\n",
       "      <td>2018-01-02 14:27:29</td>\n",
       "      <td>https://medium.freecodecamp.org/how-to-build-a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16052727</td>\n",
       "      <td>Mobile web usage finally tops desktop in December</td>\n",
       "      <td>story</td>\n",
       "      <td>gator-io</td>\n",
       "      <td>2018-01-02 16:15:39</td>\n",
       "      <td>https://netmarketshare.com/device-market-share...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16053025</td>\n",
       "      <td>Oumuamua pursued: the path of an interstellar ...</td>\n",
       "      <td>story</td>\n",
       "      <td>fanf2</td>\n",
       "      <td>2018-01-02 16:43:03</td>\n",
       "      <td>http://www.universalworkshop.com/2017/12/31/ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16053911</td>\n",
       "      <td>How Technology Is Hijacking Your Mind</td>\n",
       "      <td>story</td>\n",
       "      <td>rmason</td>\n",
       "      <td>2018-01-02 18:19:20</td>\n",
       "      <td>https://journal.thriveglobal.com/how-technolog...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16054336</td>\n",
       "      <td>Ethereum Foundation Q4 Roundup</td>\n",
       "      <td>story</td>\n",
       "      <td>sethbannon</td>\n",
       "      <td>2018-01-02 18:57:37</td>\n",
       "      <td>https://blog.ethereum.org/2018/01/02/q4-roundup/</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16054433</td>\n",
       "      <td>Fishing for Hackers 2 – Kubernetes Boogaloo</td>\n",
       "      <td>story</td>\n",
       "      <td>knoxa2511</td>\n",
       "      <td>2018-01-02 19:07:54</td>\n",
       "      <td>https://sysdig.com/blog/fishing-hackers-2-kube...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16055066</td>\n",
       "      <td>Toyota wants to change the world with Mirai, i...</td>\n",
       "      <td>story</td>\n",
       "      <td>ABS</td>\n",
       "      <td>2018-01-02 20:06:53</td>\n",
       "      <td>http://www.wired.co.uk/article/toyota-mirai-hy...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Object ID                                              Title Post Type  \\\n",
       "0    16043981  Terminal: How the airport came to embody our n...     story   \n",
       "1    16044958  Not only is it possible to beat Google, it cou...     story   \n",
       "2    16045440                      DC’s war on rats goes digital     story   \n",
       "3    16048365       Show HN: Bitcoin Arbitrage – Kraken vs. GDAX   show_hn   \n",
       "4    16050632  Handy function for Bash to display the compile...     story   \n",
       "5    16050939  Is debate around 'bias in AI' driven by human ...     story   \n",
       "6    16051647  Cryptocurrencies Are Not a Legal Tender; India...     story   \n",
       "7    16051717           Tech's Winning (and Losing) Jobs in 2018     story   \n",
       "8    16051971      Build a URL Shortener Using AWS Lambda and S3     story   \n",
       "9    16052727  Mobile web usage finally tops desktop in December     story   \n",
       "10   16053025  Oumuamua pursued: the path of an interstellar ...     story   \n",
       "11   16053911              How Technology Is Hijacking Your Mind     story   \n",
       "12   16054336                     Ethereum Foundation Q4 Roundup     story   \n",
       "13   16054433        Fishing for Hackers 2 – Kubernetes Boogaloo     story   \n",
       "14   16055066  Toyota wants to change the world with Mirai, i...     story   \n",
       "\n",
       "           Author           Created At  \\\n",
       "0        jseliger  2018-01-01 00:59:56   \n",
       "1       Nuzzerino  2018-01-01 06:16:27   \n",
       "2          fern12  2018-01-01 09:37:22   \n",
       "3        BigBalli  2018-01-01 22:21:21   \n",
       "4         ikromin  2018-01-02 08:19:13   \n",
       "5       imartin2k  2018-01-02 09:49:43   \n",
       "6   techaddict009  2018-01-02 13:15:06   \n",
       "7      SunTzu9087  2018-01-02 13:30:45   \n",
       "8         dan9408  2018-01-02 14:27:29   \n",
       "9        gator-io  2018-01-02 16:15:39   \n",
       "10          fanf2  2018-01-02 16:43:03   \n",
       "11         rmason  2018-01-02 18:19:20   \n",
       "12     sethbannon  2018-01-02 18:57:37   \n",
       "13      knoxa2511  2018-01-02 19:07:54   \n",
       "14            ABS  2018-01-02 20:06:53   \n",
       "\n",
       "                                                  URL  Points  \\\n",
       "0   http://www.slate.com/articles/business/cover_s...      97   \n",
       "1   https://www.quora.com/Is-it-possible-to-beat-G...      92   \n",
       "2   https://wamu.org/story/17/12/18/d-c-s-war-rats...      31   \n",
       "3                 http://giacomoballi.com/crypto.html      11   \n",
       "4   https://www.igorkromin.net/index.php/2018/01/0...       2   \n",
       "5   http://donaldclarkplanb.blogspot.com/2017/12/i...       1   \n",
       "6   https://cryptocrimson.com/cryptocurrencies-not...       2   \n",
       "7   https://insights.dice.com/2018/01/02/tech-winn...       1   \n",
       "8   https://medium.freecodecamp.org/how-to-build-a...       1   \n",
       "9   https://netmarketshare.com/device-market-share...       2   \n",
       "10  http://www.universalworkshop.com/2017/12/31/ou...       1   \n",
       "11  https://journal.thriveglobal.com/how-technolog...       2   \n",
       "12   https://blog.ethereum.org/2018/01/02/q4-roundup/       3   \n",
       "13  https://sysdig.com/blog/fishing-hackers-2-kube...       1   \n",
       "14  http://www.wired.co.uk/article/toyota-mirai-hy...       3   \n",
       "\n",
       "    Number of Comments  year  \n",
       "0                 73.0  2018  \n",
       "1                125.0  2018  \n",
       "2                 53.0  2018  \n",
       "3                  6.0  2018  \n",
       "4                  0.0  2018  \n",
       "5                  0.0  2018  \n",
       "6                  0.0  2018  \n",
       "7                  0.0  2018  \n",
       "8                  0.0  2018  \n",
       "9                  1.0  2018  \n",
       "10                 0.0  2018  \n",
       "11                 0.0  2018  \n",
       "12                 0.0  2018  \n",
       "13                 0.0  2018  \n",
       "14                 3.0  2018  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Feature Engineer the Created At column to get the year from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYear(str):\n",
    "    return int(str.split('-')[0])\n",
    "\n",
    "df['Formatted Year'] = df['Created At'].apply(getYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    5000\n",
       "2018    5000\n",
       "Name: Formatted Year, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Formatted Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's form our train and test Split  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets split the given title with their post type and year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_YEAR = 2018\n",
    "TEST_YEAR = 2019\n",
    "DOCUMENT_TYPES = df['Post Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainData():\n",
    "    originalTrainData = []\n",
    "    for type in DOCUMENT_TYPES:\n",
    "        tmp =  df[(df['Post Type'] == type) & (df['Formatted Year'] == TRAIN_YEAR)]['Title']\n",
    "        originalTrainData.append(list(tmp))\n",
    "    return originalTrainData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTestData():\n",
    "    originalTestData = []\n",
    "    for type in DOCUMENT_TYPES:\n",
    "        tmp =  df[(df['Post Type'] == type) & (df['Formatted Year'] == TEST_YEAR)]['Title']\n",
    "        originalTestData.append(list(tmp))\n",
    "    return originalTestData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we need to deal with the stopwords so i will define a function that removes them if they occur from a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [line.rstrip('\\n') for line in open('../data/stopwords.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to define our classes and datastructures that will help us to store and count all the different words we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "import numpy as np\n",
    "\n",
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, type):\n",
    "        self.titleCount = 0\n",
    "        self.numberOfWords = 0\n",
    "        self.vocabulary = {}\n",
    "        self.TYPE = type\n",
    "        \n",
    "    def addWord(self, str):\n",
    "        if str in self.vocabulary:\n",
    "            self.vocabulary[str] += 1\n",
    "        \n",
    "        else:\n",
    "            self.vocabulary[str] = 1\n",
    "\n",
    "        self.numberOfWords += 1\n",
    "\n",
    "    def containsWord(self, str):\n",
    "        if str in self.vocabulary:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def getWordOccurences(self, str):\n",
    "        if str in self.vocabulary:\n",
    "            return self.vocabulary[str]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def getProbability(self, word, numberOfUniqueWords, smoothing = 0.5):\n",
    "        if(word in self.vocabulary):\n",
    "            return (self.vocabulary[word] + smoothing)/(self.numberOfWords + numberOfUniqueWords*smoothing)\n",
    "        else:\n",
    "            return smoothing/(self.numberOfWords + numberOfUniqueWords*smoothing)\n",
    "\n",
    "    def increaseTitleCount(self):\n",
    "        self.titleCount += 1\n",
    "\n",
    "    def removeElements(self, threshold = 0, percentage = False):\n",
    "        \n",
    "        thres = 0\n",
    "\n",
    "        if(percentage):\n",
    "            frequencies = np.array(list(self.vocabulary.values()))\n",
    "            thres = np.quantile(frequencies, (1-threshold/100))\n",
    "\n",
    "        else:\n",
    "            thres = threshold\n",
    "\n",
    "        self.vocabulary = {key:val for key, val in self.vocabulary.items() if int(val) < thres} \n",
    "        self.numberOfWords = len(self.vocabulary)   \n",
    "\n",
    "class Lexicon:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.dictionaries = []\n",
    "        \n",
    "        for dictionary in args:\n",
    "            self.dictionaries.append()\n",
    "\n",
    "    def getOccurences(self, str):\n",
    "        occurences = {}\n",
    "        for dictionary in self.dictionaries:\n",
    "            type = dictionary.TYPE\n",
    "            occurences[type] = dictionary.getWordOccurences(str)\n",
    "        return occurences\n",
    "\n",
    "    def addDictionary(self, dictionary):\n",
    "        self.dictionaries.append(dictionary)\n",
    "\n",
    "    def getInformation(self):\n",
    "        for dictionary in self.dictionaries:\n",
    "            print('------{}------'.format(dictionary.TYPE))\n",
    "            print('Number Of Unique Words: {}'.format(len(dictionary.vocabulary)))\n",
    "            print('Number Of Words: {}'.format(dictionary.numberOfWords))\n",
    "            print('Title Count: {} \\n'.format(dictionary.titleCount))\n",
    "\n",
    "class BayesModel:\n",
    "\n",
    "    def __init__(self, data, removeStopWords = False , min = -1, max = float('inf')):\n",
    "        self.setOfWords = set()\n",
    "        self.totalNumberOfTitles = 0\n",
    "        self.removeStopWords = removeStopWords\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        self.lexicon = self.formLexicon(data)\n",
    "\n",
    "    def formLexicon(self,data):\n",
    "        lexicon = Lexicon()\n",
    "        \n",
    "        for x in range(len(data)):\n",
    "            dictionary = Dictionary(DOCUMENT_TYPES[x])\n",
    "            \n",
    "            for title in data[x]:\n",
    "                dictionary.increaseTitleCount()\n",
    "                title = self.formatTitle(title)\n",
    "                for word in title.split():\n",
    "                    if (self.removeStopWords and word in stopwords) or word == '' or self.applyFilter(word):\n",
    "                        continue\n",
    "                    dictionary.addWord(word)\n",
    "                    self.setOfWords.add(word)\n",
    "            self.totalNumberOfTitles += dictionary.titleCount\n",
    "            lexicon.addDictionary(dictionary)\n",
    "        \n",
    "        self.setOfWords = sorted(self.setOfWords)\n",
    "        return lexicon\n",
    "\n",
    "\n",
    "    def classifyTitle(self, sentence, smoothing = 0.5):\n",
    "        sentence = self.formatTitle(sentence)\n",
    "        listOfWords = sentence.split()\n",
    "        titleType = ''\n",
    "        probability = float(\"-inf\")\n",
    "        probabilities = []\n",
    "        for dictionary in self.lexicon.dictionaries:\n",
    "            dictProbability = log10(dictionary.titleCount/self.totalNumberOfTitles)\n",
    "            for word in listOfWords:\n",
    "                if self.removeStopWords and word in stopwords or self.applyFilter(word):\n",
    "                    continue\n",
    "                dictProbability += log10(dictionary.getProbability(word.strip(), len(self.setOfWords),smoothing))\n",
    "            probabilities.append(dictProbability)\n",
    "            if(dictProbability > probability):\n",
    "                probability = dictProbability\n",
    "                titleType = dictionary.TYPE\n",
    "        probabilities.append(titleType)\n",
    "        return probabilities\n",
    "    \n",
    "    def switchStopWords(self):\n",
    "        self.removeStopWords = not self.removeStopWords\n",
    "        print('remove stop words: {}'.format(self.removeStopWords))\n",
    "\n",
    "    def formatTitle(self, sentence):\n",
    "        for c in '^!\"#$%&()*+,./:;<=>?@[\\\\]^\\'`{|}~\"-”“’‘ꓘ√—–«ð':\n",
    "            sentence = sentence.replace(c,' ')\n",
    "        return sentence.lower().strip()\n",
    "\n",
    "    def createModelFile(self,fileTxt,smoothing = 0.5):\n",
    "        f = open(fileTxt, 'w',encoding=\"utf-8\")\n",
    "        counter = 1\n",
    "        for word in self.setOfWords:\n",
    "            out = '{}  {}  '.format(counter, word)\n",
    "            for dictionary in self.lexicon.dictionaries:\n",
    "                out = out + '{}  {}  '.format(\n",
    "                    dictionary.getWordOccurences(word),\n",
    "                    dictionary.getProbability(word, len(self.setOfWords),smoothing)\n",
    "                )\n",
    "            f.write(out + '\\n')\n",
    "            counter += 1\n",
    "        f.close()\n",
    "\n",
    "    def createClassificationFile(self, fileTxt, testData, smoothing = 0.5):\n",
    "        f = open(fileTxt, 'w',encoding=\"utf-8\")\n",
    "        counter = 1\n",
    "        for index in range(len(testData)):\n",
    "            for title in testData[index]:\n",
    "                results = self.classifyTitle(title)\n",
    "                out = '{}  {}  {}  '.format(counter,title,results[-1])\n",
    "                for score in results[:-1]:\n",
    "                    out = '{}  {:.2f}  '.format(out, score)\n",
    "                if(results[-1] == DOCUMENT_TYPES[index]):\n",
    "                    out = '{}  {}  {}'.format(out,DOCUMENT_TYPES[index], 'right')\n",
    "                else:\n",
    "                    out = '{}  {}  {}'.format(out,DOCUMENT_TYPES[index], 'wrong')\n",
    "                f.write(out + '\\n')\n",
    "                counter += 1\n",
    "        f.close()\n",
    "\n",
    "    def applyFilter(self, str):\n",
    "        if(len(str) <= self.min or len(str) >= self.max):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def removeLeastFrequent(self, threshold, percentage = False):\n",
    "        for dictionary in self.lexicon.dictionaries:\n",
    "            dictionary.removeElements(threshold, percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Task 3: Experiments with the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Build the model without worrying about the stop words and ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstTrainData = generateTrainData()\n",
    "firstTestData = generateTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "model = BayesModel(firstTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------story------\n",
      "Number Of Unique Words: 9486\n",
      "Number Of Words: 38248\n",
      "Title Count: 4572 \n",
      "\n",
      "------show_hn------\n",
      "Number Of Unique Words: 905\n",
      "Number Of Words: 1978\n",
      "Title Count: 206 \n",
      "\n",
      "------ask_hn------\n",
      "Number Of Unique Words: 843\n",
      "Number Of Words: 2401\n",
      "Title Count: 222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.lexicon.getInformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.createModelFile('../data/vocabulary.txt')\n",
    "model.createClassificationFile('../data/baseline-result.txt.txt',firstTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.1 Experiment 1: Stop-word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondTrainData = generateTrainData()\n",
    "secondTestData = generateTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordModel = BayesModel(secondTrainData, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------story------\n",
      "Number Of Unique Words: 9348\n",
      "Number Of Words: 26897\n",
      "Title Count: 4572 \n",
      "\n",
      "------show_hn------\n",
      "Number Of Unique Words: 861\n",
      "Number Of Words: 1601\n",
      "Title Count: 206 \n",
      "\n",
      "------ask_hn------\n",
      "Number Of Unique Words: 753\n",
      "Number Of Words: 1537\n",
      "Title Count: 222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopWordModel.lexicon.getInformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordModel.createModelFile('../data/stopword-model.txt')\n",
    "stopWordModel.createClassificationFile('../data/stopword-result.txt', secondTrainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.2 Experiment 2: Word Length Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdTrainData = generateTrainData()\n",
    "thirdTestData = generateTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthModel = BayesModel(firstTrainData, True, 2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthModel.createModelFile('../data/length-vocabulary.txt')\n",
    "lengthModel.createClassificationFile('../data/length-result.txt.txt',thirdTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.3 Experiment 3: Infrequent Word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "FourthTrainData = generateTrainData()\n",
    "FourthTestData = generateTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredModel = BayesModel(FourthTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(model.lexicon.dictionaries[2].vocabulary.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.899999999999977"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(a,.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
